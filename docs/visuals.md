# Visualization Guide

This document explains the various plots generated by the `visualize_paper.py` script and the training pipeline.

## 1. Training & Validation

### `training_loss.png`
*   **Description:** Plots the Huber Loss over training epochs.
*   **Interpretation:** A downward curve indicates the model is learning. If the validation loss tracks the training loss, the model is generalizing well (not overfitting).

### `inference_plot.png`
*   **Description:** Scatter plot of Predicted Loss vs. Actual Loss (Ground Truth).
*   **Interpretation:** Points should cluster tightly around the diagonal ($y=x$) line. The $R^2$ value in the title quantifies accuracy (closer to 1.0 is better).

## 2. Paper Figures (Publication Quality)

### `paper_fig_tsne.png`
*   **Description:** t-SNE embedding of the learned node features.
*   **Interpretation:** Shows how the GNN groups similar components. You should see distinct clusters for Buses, PVs, and Chargers, proving the model understands physical heterogeneity.

### `paper_fig_landscape.png`
*   **Description:** Histogram of power losses for 1000+ random topologies in a single scenario.
*   **Interpretation:** Demonstrates the difficulty of the problem. The "Optimal" line (red) shows the solution found by the GNN, which should be far to the left (lower loss) of the average distribution.

### `paper_fig_heatmap.png`
*   **Description:** A "DNA" map of the top 50 best topologies. Rows are topologies, columns are switches.
*   **Interpretation:** Dark/Light vertical bands indicate "Critical Switches" that must always be Open or Closed to achieve high performance.

### `paper_fig_voltage.png`
*   **Description:** Voltage profile along a feeder line.
*   **Interpretation:** Compares the Baseline (Red) vs. Optimized (Green). The optimized line should stay closer to 1.0 p.u. and avoid dropping below the 0.95 limit.

### `paper_fig_24h.png`
*   **Description:** 24-hour simulation of system losses.
*   **Interpretation:** Shows the cumulative benefit of real-time control. The area between the Grey (Passive) and Green (AI) lines represents energy saved.

### `paper_fig_speedup.png`
*   **Description:** Bar chart comparing inference time.
*   **Interpretation:** Highlights the massive speed advantage of the GNN (milliseconds) vs. the traditional solver (tens of milliseconds), plotted on a log scale.